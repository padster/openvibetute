<html>
  <head>
    <link rel="stylesheet" href="./reveal.css">
    <link rel="stylesheet" href="./white.css">
    <link rel="stylesheet" href="./custom.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <section>
            <h2>So you want to read minds?</h2>
            You can't (yet), but we'll talk about what you can do... <br /> <br />
            <img width='70%' src='./img/devices.png' />
          </section>
          <section>
            <h2>Today</h2>
            <ol>
              <li>Introduction to EEG</li>
              <li>Walk through EEG terms and technology using OpenVibe</li>
              <li>Given enough pointers for people trying their own experiments</li>
            </ol>
          </section>
          <section>
            <h2>Hi!</h2>
            Patrick Coleman
            <div style="display: flex" />
            <img src='./img/profilePic.jpg' style="height: 196px; width: 196px; align-self: center;" />
            <div style="padding-left: 16px">
              <ul>
                <li>Former: software engineer / maths student.</li>
                <li>Now: Going into neuroscience, specializing in data processing.</li>
                <li>Member of Vancouver NeuroTechX</li>
                <li>Code: <a href="http://github.com/padster">http://github.com/padster</a></li>
                <li>Blog: <a href="http://github.com/padster">https://padsterprogramming.blogspot.com</a></li>
              </ul>
            </div>
          </section>
        </section>

        <section>
          <section>
            <h2>Intro: What are brains?</h2>
            Very abstractly...a giant connected information network. <br />
            <ul>
              <li>Nodes = <b>Neurons</b>, ~100 billion (?)
              <li>Edges = <b>Synapses</b>, ~100 trillion (?)
              <li>Signal = electrical current
            </ul> <br /> <br />
            plus lots of other things (glial cells, neurotransmitters, blood, ...)
          </section>
          <section>
            <h2>What is EEG?</h2>
            Sensors to read electrical signal.
            <ul>
              <li>Non-invasive!</li>
              <li>Good temporal resolution: Fast</li>
              <li>Bad spatial resolution: measure voltage <i>on scalp</i></li>
              <li>Lots of <a href="http://www.math.tau.ac.il/~nin/Courses/Seminar14a/EEG_AlphaTheta1999.pdf">research</a>
                into <a href="https://mitpress.mit.edu/books/introduction-event-related-potential-technique">what</a>
                can be <a href="https://www.ncbi.nlm.nih.gov/pubmed/10686361">identified</a>.</li>
              <li>Sensitive: voltage is around ÂµV, susceptible to movement, ...</li>
            </ul>
            <img width='30%' src='./img/neurons.png' />
          </section>
          <section>
            <h2>Example!</h2>
            <ul>
              <li>X axis = Time</li>
              <li>Y axis = Voltage, one row per sensor</li>
            </ul>
            <img width='80%' src='./img/eegExample.png' />
            How to measure? How to process? ...
          </section>
        </section>

        <section>
          <section>
            <h2>Measure example: <a href='http://openbci.com'>OpenBCI</a></h2>
            Hardware and software for running your own EEG system.
            <img src='./img/bciCyton.jpg' />
          </section>
          <section>
            <h2>Process example: <a href='http://openvibe.inria.fr'>OpenVibe</a></h2>
            Software specializing in real-time processing of brain signals. <br />
            Good for prototyping (and explaining) things!</br /> <br />
            <iframe width="560" height="315" src="https://www.youtube.com/embed/poX_DVB711o" frameborder="0" allowfullscreen></iframe>
          </section>
        </section>

        <section>
          <section>
            <h2>Installing OpenVibe...</h2>
            <ul>
              <li>Visit the OpenVibe website <a href="http://openvibe.inria.fr/downloads/">downloads page</a></li>
              <li>At time of writing, <b>v1.3.0</b> supports windows and linux</li>
            </ul>
          </section>
          <section>
            <h2>...Run the Designer</h2>
            <pre><code data-trim>~/openvibe$ ./dist/openvibe-designer.sh</code></pre>
            <img src='./img/Designer.png' />
          </section>
          <section>
            <h2>...What is going onâ€½â€½</h2>
            <b>Noise generator</b>: Generate fake EEG time series. <br />
            <b>Signal display</b>: Display the time series. <br />
            Now play with some settings! <br />
            <img src='./img/ScanSettings.png' />
          </section>
        </section>

        <section>
          <section>
            <h2>Option: use existing data</h2>
            Some public EEG data sets exist - UCSD has a <a href="https://sccn.ucsd.edu/~arno/fam2data/publicly_available_EEG_data.html">good collection</a>.
            We'll use the 2015 Music BCI data set available from <a href="http://bnci-horizon-2020.eu/database/data-sets">BCNI Horizon</a> (set #15), with paper
            describing the data from <a href="http://doc.ml.tu-berlin.de/bbci/BNCIHorizon2020-MusicBCI/BNCI_MusicBCI.pdf">TU Berlin</a>. <br /> <br />
            <b>Warning: 554Mb!</b> EEG data is big...
          </section>
        </section>

        <section>
          <section>
            <h2>Load and Visualize</h2>
            <br />
            Lots of data formats, chances are you'll need some processing...<br />
            <br />
            <span style="font-size: 150%">â˜¹</span> <br />
            <br />
            A bunch are supported (see the <a href="http://openvibe.inria.fr/supported-file-formats/">list</a>), <br />
            for now we'll use the <a href="http://openvibe.inria.fr/documentation/1.3.0/Doc_BoxAlgorithm_CSVFileReader.html">CSV Reader</a> and some python.
          </section>
          <section>
            <h2>Rewrite signal values into CSV format</h2>
<pre><code class="py" data-trim>  import scipy.io as sio
  import csv

  SUBJECT = 'aak'
  IN_FILE = 'data/musicbci_VP%s.mat' % SUBJECT
  OUT_FILE = 'dataCSV/%s_signal.csv' % SUBJECT

  print "Loading matlab file %s..." % IN_FILE
  data = sio.loadmat(IN_FILE)
  readings = data['data'][0]['X'][0]

  # First line: Row count, then channel names, then sample rate
  channelNames = [str(c[0]) for c in data['data'][0]['clab'][0][0]]
  sampleRate = data['data'][0]['fs'][0][0][0]

  print "# Readings: %d" % readings.shape[0]
  print "# Channels: %d" % len(channelNames)
  print "Sample rate: %d hz" % sampleRate

  # sampleRate samples/sec = 1000 / sampleRate ms/sample
  secPerSample = 1.0 / sampleRate

  print "Writing to %s..." % OUT_FILE
  with open(OUT_FILE, 'wb') as csvfile:
      writer = csv.writer(csvfile)
      writer.writerow(['Time (s)'] + channelNames + ['Sampling Rate'])
      # First row has extra rate:
      writer.writerow([0.0] + readings[0].tolist() + [sampleRate])
      for r in range(1, readings.shape[0]):
          writer.writerow([r * secPerSample] + readings[r].tolist())

  print "Done!"</code></pre>
            Also available on <a href="https://github.com/padster/openvibetute/blob/master/code/signalToCSV.py">github</a>
          </section>
          <section>
            <h2>Run conversion...</h2>
<pre><code class="sh" data-trim>~/openvibe/musicbci$ time python signalToCSV.py
Loading matlab file data/musicbci_VPaak.mat...
# Readings: 2277240
# Channels: 64
Sample rate: 200 hz
Writing to dataCSV/aak_signal.csv...
Done!

real	2m30.080s
user	2m25.902s
sys	0m3.841s</code></pre>
          </section>
          <section>
            <h2>View in Designer</h2>
            Enable <a href="http://openvibe.inria.fr/faq/#unstable">unstable</a> boxes to use CSVFileReader.
            <img src="./img/BCIDataLoaded.png" />
          </section>
        </section>

        <section>
          <section>
            <h2><i>Concept</i>: Frequency Analysis</h2>
            Different frequencies in the signal are correlated to different things:
            <table>
              <thead><tr><td>Type</td><td>Frequency</td><td>Association (ish...)</td></tr></thead>
              <tbody>
                <tr><td>Delta</td><td>0.1 - 3Hz</td><td>Sleep, Healing</td></tr>
                <tr><td>Theta</td><td>4 - 7Hz</td><td>Meditation, Memory</td></tr>
                <tr><td>Alpha</td><td>8 - 15Hz</td><td>Relaxation, Creativity</td></tr>
                <tr><td>Beta</td><td>16 - 30Hz</td><td>Alertness, Cognition</td></tr>
                <tr><td>Gamma</td><td>31 - 100Hz</td><td>Focus, Consciousness</td></tr>
              </tbody>
            </table>
          </section>
          <section>
            <h2>Power bands in designer</h2>
            To set it up... <br />
            <ol>
              <li>Read signal from CSV, as before.</li>
              <li>Use <i>Channel selector</i> box to pick some channels.</li>
              <li>Convert to frequencies with <i>Spectral Analysis (FFT)</i></li>
              <li>Draw to screen with <i>Power spectrum display</i></li>
            </ol>
          </section>
          <section>
            <h2>Result</h2>
            <img width='70%' src='./img/psd.png' />
            NB: Historgram looks bad :( One place where OpenVibe isn't great. <br />
            The <a href="http://openbci.com/images/v2-2.gif">display</a> from OpenBCI is much nicer...
          </section>
          <section>
            <h2><i>Example:</i> Alpha Waves</h2>
            <ul>
              <li>Add <i>Temporal filter</i> to restrict to 8-15Hz</li>
              <li>Display the result with the usual signal display</li>
              <li>Also add a <i>Spectrum average</i> and display with <i>Matrix display</i></li>
            </ul>
            <img src='./img/alphaFilter.png' />
          </section>
        </section>

        <section>
          <section>
            <h2><i>Concept</i>: ICA</h2>
            <b>I</b>ndependant <b>C</b>omponent <b>A</b>nalysis is where multiple signals can be separated out into independant parts. Useful for:
            <ul>
              <li>Noise reduction: find the 'blink' component, and remove it</li>
              <li>Virtual channels: e.g. reduce to 'frontal' signal, 'left hemisphere', ...</li>
            </ul>
          </section>
          <section>
            <h2>Localization</h2>
            There is a standard '10-20' placement system:
            <img src='./img/1020.gif' /> <br />
            For this example, we'll look at F7/F9, and P8/P10.
          </section>
          <section>
            <h2>In Designer</h2>
            <ul>
              <li>Apply channel selection for P8;P10;F7;F9</li>
              <li>Run through <i>Independant Component Analysis</i> box</li>
            </ul>
            <img src='./img/ica.png' />
            IC1 ~ front left, IC2 ~ back right.
          </section>
        </section>

        <section>
          <section>
            <h2><i>Concept</i>: Events</h2>
            Some applications for EEG look at signal after an event happens. <br />
            OpenVibe calls these <i>'stimulations'</i>.
            <img src='./img/erp.jpg' height="50%"/>
            <b>BUT</b>: You need timings for events
          </section>
          <section>
            <h2>Rewrite CSV format</h2>
<pre><code class="py" data-trim>
  import scipy.io as sio
  import csv

  SUBJECT = 'aak'
  IN_FILE = 'data/musicbci_VP%s.mat' % SUBJECT
  OUT_FILE = 'dataCSV/%s_events.csv' % SUBJECT

  print "Loading matlab file %s..." % IN_FILE
  data = sio.loadmat(IN_FILE)

  trials = data['data'][0]['trial'][0]
  values = data['data'][0]['y'][0]
  assert trials.shape == values.shape

  eventCount = trials.shape[1]
  sampleRate = int(round(data['data'][0]['fs'][0][0][0]))
  print "# Events: %d" % eventCount

  print "Writing to %s..." % OUT_FILE
  with open(OUT_FILE, 'wb') as csvfile:
  writer = csv.writer(csvfile)
  writer.writerow(['Time (s)', 'Identifier', 'Duration'])
  # First row has extra rate:
  for i in range(eventCount):
  msOffset = int(round(trials[0, i])) * 1000 / sampleRate
  # eID = values[0, i]
  eID = 33024 + values[0, i] # HACK: http://openvibe.inria.fr/stimulation-codes/
  writer.writerow([msOffset / 1000.0, eID, 1])

  print "Done!"
</code></pre>
          Also available on <a href="https://github.com/padster/openvibetute/blob/master/code/eventsToCSV.py">github</a>
          </section>
          <section>
            <h2>In Designer</h2>
            <i>CSV File Reader</i>
            <ul>
              <li>Right-Click ðŸ¡º Modify Outputs ðŸ¡º Output Stream ðŸ¡º Stimulations</li>
              <li>Purple arrow = correct (see <a href="http://openvibe.inria.fr/stream-structures/">here</a>)</li>
            </ul>
            <img src='./img/events.png' />
          </section>
        </section>

        <section>
          <section>
            <h2><i>Concept</i>: Event Related Potentials (ERPs)</h2>
            Lots of research into what is expected after certain stimuli! <br />
            e.g. <a href="https://en.wikipedia.org/wiki/P300_(neuroscience)">P300</a> is fairly stable, and can be decoded with
            <a href="https://github.com/alexandrebarachant/muse-lsl/blob/master/notebooks/P300%20with%20Muse.ipynb">Muse</a>. <br />
            <ul>
              <li>P = <b>P</b>ositive voltage (= down...)</li>
              <li>300 = <b>300</b> milliseconds after stimulus
            </ul>
            <img src='./img/p300.png' />
            N.B: This is an average <i>'epoch'</i> = segment of signal.
          </section>
          <section>
            A bit more involved... <br />
            <ul>
              <li>Two CSV readers, load signal and events</li>
              <li>Filter for some channels (for simplicity)</li>
              <li>Stimulation-based epoching</li>
              <ul><li><a href="http://openvibe.inria.fr/stimulation-codes/">OVTK_StimulationId_Label_03</a> used</li></ul>
              <li>Draw with signal display, plus ERP plot</li>
            </ul>
            <img src='./img/erpShow.png' />
          </section>
          <section>
            <h2>Extra</h2>
            <ul>
              <li><i>Epoch Variance</i> box allows the calculation of the mean and variance across multiple epochs.</li>
              <li><i>ERP plot</i> can also save the result to file on a particular signal.</li>
            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2><i>Concept</i>: Localization</h2>
            Given positions of sensors on the scalp, can we convert them back to find signal strength at locations internally? <br />
            <a href="http://www.scholarpedia.org/article/Source_localization">LOTS of techniques</a>
            (Dipole modelling, Beam forming, Bayesian MAP, sLORETA), ...no clear winner.
          </section>
          <section>
            <h2>In Designer, 2D</h2>
            <ul>
              <li>Load data from CSV, as before, and exclude "EOGvu" (reference).</li>
              <li>Load locations from .txt, using localization file reader.</li>
              <li>Display with <i>2D Topographic Map</i>.</li>
            </ul>
            <img src='./img/2dtop.png' height="50%"/>
          </section>
          <section>
            <h2>Bonus! '3D'</h2>
            <img src='./img/3dtop.png' />
            N.B: You should create your own locations, but see openvibe/dist/share/openvibe/electrode_sets for an example.
          </section>
        </section>

        <section>
          <section>
            <h2>Live streaming!</h2>
            We can process from old files, can we process from new live data?<br />
            OpenVibe supports live data too, using the <i>Acquisition server.</i>
          </section>
          <section>
            <h2>Acquisition Server</h2>
            Used to input data live from device, but can also read from file or make random signal.
            <pre><code data-trim>~/openvibe$ ./dist/openvibe-acquisition-server.sh</code></pre>
            <img src='./img/AcquisitionServer.png' />
          </section>
          <section>
            <h2>Muse (via LSL)</h2>
            To get Muse working with OpenVibe, the simplest way is to get them both talking the LSL format
            (= <a href="https://github.com/sccn/labstreaminglayer"><b>L</b>ab <b>S</b>treaming <b>L</b>ayer</a>). <br />
            <br />
            <h4>1) Muse -> LSL</h4>
            <pre><code data-trim>$~/muse$ muse-io --device DEVICE_ID --lsl-eeg muse </code></pre>
            Enter your Muse bluetooth ID for DEVICE_ID, for example mine is 00:06:66:68:9F:96 <br />
            <b>N.B:</b> With newer Muse, you'll want the <a href="https://github.com/alexandrebarachant/muse-lsl">muse-lsl</a> library.
          </section>
          <section>
            <h4>2) LSL -> Aquisition Server</h4>
            <img src='./img/lslServer.png' />
            <ol>
              <li>Select signal stream to the name above, and marker to None.</li>
              <li><b>Connect</b> to your device, make sure it's successful</li>
              <li><b>Play</b> to start the streaming</li>
            </ol>
          </section>
          <section>
            <h4>View in designer</h4>
            <ul>
              <li><i>Acquisition client</i> box to read from the server</li>
              <li>Connect to the stream visualizer (or whatever you like)</li>
            </ul>
            <img src='./img/museLive.png' />
          </section>
          <section>
            <h2>OpenBCI</h2>
            OpenBCI makes this even easier, <br />with the Acquisition server supporting it by default.<br />
            <h4>1) OpenBCI to 'PC' mode and plug in USB</h4>
            <img src='./img/openBCIUSB.png' />
          </section>
          <section>
            <h4>2) Aquisition server:</h4>
            <img src='./img/openBCIServer.png' />
          </section>
          <section>
            <h2>Saving...</h2>
            <div style="display: flex">
              <img src='./img/saveFile.png' />
              <div style='align-self: center'> ðŸ¢‚ </div>
              <img src='./img/loadFile.png' />
            </div>
            <div style="clear: float;" />
            <br />
            <b>N.B.</b>: Need to set the types to Signal
          </section>
        </section>

        <section>
          <section>
            <h2>More on OpenVibe...</h2>
            <br />
            Some extra stuff that wasn't covered, but for those interested...
            <br /><br />
            <ul>
              <li><i>Connectivity</i> box for <a href='http://openvibe.inria.fr/documentation/1.0.0/Doc_BoxAlgorithm_ConnectivityMeasure.html'>synchronicity</a>
                 between various parts of the brain.</li>
              <li>Automatic Classification <i>trainer</i> and <i>processor</i>: use machine learning techniques (SVM, LDA) to learn how to identify various events, if possible</li>
            </ul>
          </section>
          <section>
            <h2>Thanks!</h2>
            padsterpat@gmail.com <br />
            https://github.com/padster <br />
          </section>
          <section>
            <h2>More on <a href="http://neurotechx.com/">NeuroTechX</a>...</h2>
            International non-profit building a community of neuro technology enthusiasts.
            <ul>
              <li>Join the slack: <a href="https://neurotechx.herokuapp.com/">https://neurotechx.herokuapp.com/</a></li>
              <li>Keep an eye on future events in Vancouver, posted on <a href="https://www.meetup.com/NeuroTechVAN/">Meetup</a></li>
            </ul>
          </section>
        </section>

      </div>

    </div>
    <script src="./reveal.js"></script>
    <script>
      Reveal.initialize({
        history: true,
        slideNumber: 'c/t',
      });
      hljs.initHighlightingOnLoad();
    </script>
  </body>
</html>
